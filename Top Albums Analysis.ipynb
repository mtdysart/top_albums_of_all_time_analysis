{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the data from the Top Albums of All Time\n",
    "\n",
    "### Sputnikmusic\n",
    "We need to get the content from the top albums of all time list. To do this, we first use Selenium webdriver to select 'all time' from the dropdown list. Then we can extract the content into a BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 85.0.4183\n",
      "[WDM] - Get LATEST driver version for 85.0.4183\n",
      "[WDM] - Driver [C:\\Users\\mattd\\.wdm\\drivers\\chromedriver\\win32\\85.0.4183.87\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "def get_sput_alltime():\n",
    "    \"\"\"\n",
    "    Returns a Beautiful Soup object containing the contents of the Top Albums of All Time page from sputnikmusic.com.\n",
    "    Returns None if content fails to load.\n",
    "    \"\"\"\n",
    "    \n",
    "    current_year = \"2020\"\n",
    "    rankings_url = \"https://www.sputnikmusic.com/best/albums/\" + current_year + \"/\"\n",
    "\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.maximize_window()\n",
    "    driver.get(rankings_url)\n",
    "\n",
    "    time.sleep(5)\n",
    "    content = driver.page_source.encode('utf-8').strip()\n",
    "\n",
    "    if content is not None:\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        # Find the correct id for the dropdown\n",
    "        yr_dd = soup.find(\"span\", text=current_year)\n",
    "        dd_id = yr_dd.parent.parent.get('id')\n",
    "\n",
    "        # Select 'All Time' from the dropdown\n",
    "        driver.find_element_by_id(dd_id).click()\n",
    "        driver.find_element_by_id(dd_id + \"_o_2\").click()\n",
    "\n",
    "        # Wait for webpage to load and then create the parse tree from the HTML\n",
    "        time.sleep(5)\n",
    "        content_all_time = driver.page_source.encode('utf-8').strip()\n",
    "\n",
    "        if content_all_time is not None:\n",
    "            soup_all_time = BeautifulSoup(content_all_time, 'html.parser')\n",
    "            driver.quit()\n",
    "            \n",
    "            return soup_all_time\n",
    "\n",
    "\n",
    "    driver.quit()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a pandas DataFrame object from the data obtained above and store it in a variable called data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                Artist                                          Album  \\\n",
      "0      1            Pink Floyd                             Wish You Were Here   \n",
      "1      2  Ludwig van Beethoven             Symphony No. 9 in D minor, Op. 125   \n",
      "2      3        Charles Mingus            The Black Saint and the Sinner Lady   \n",
      "3      4                   Nas                                       Illmatic   \n",
      "4      5           Miles Davis                                   Kind of Blue   \n",
      "..   ...                   ...                                            ...   \n",
      "195  196           Suffocation                            Pierced from Within   \n",
      "196  197         Leonard Cohen                         Songs of Leonard Cohen   \n",
      "197  198            Koji Kondo  The Legend of Zelda 25th Anniversary Symphony   \n",
      "198  199             Sigur Ros                                 AgÃ¦tis byrjun   \n",
      "199  200                Slayer                                 Reign in Blood   \n",
      "\n",
      "    Score Ratings  \n",
      "0    4.64    6635  \n",
      "1    4.63     469  \n",
      "2     4.6    1030  \n",
      "3     4.6    3537  \n",
      "4     4.6    2394  \n",
      "..    ...     ...  \n",
      "195  4.38    1200  \n",
      "196  4.37     631  \n",
      "197  4.37     158  \n",
      "198  4.37    2621  \n",
      "199  4.37    4797  \n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_data_frame(soup):\n",
    "    \"\"\"\n",
    "    Creates the main data frame for the all-time list.\n",
    "    \"\"\"\n",
    "    \n",
    "    table = soup.find(\"tr\", class_=\"alt1\").parent.parent\n",
    "    cells = table.find_all(\"td\", class_=\"blackbox\")\n",
    "    \n",
    "    common_str = \" votes\"\n",
    "    data = []\n",
    "    for i in range(0, len(cells), 2):\n",
    "        row = {}\n",
    "        row['Rank'] = str(int(cells[i].text)) # Remove leading 0's\n",
    "        \n",
    "        fonts = cells[i+1].find_all(\"font\")\n",
    "        row['Artist'] = fonts[0].text \n",
    "        row['Album'] = fonts[1].text\n",
    "        row['Score'] = fonts[3].text\n",
    "        row['Ratings'] = fonts[4].text[: -len(common_str)]\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "    \n",
    "data = create_data_frame(soup_all_time)\n",
    "print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the data on this page does not include the release year or genre(s) of each album, so we need to scrape those from their corresponding album and artist pages respectively. This needs to be done carefully so as to not overload the site with many requests per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_links(soup):\n",
    "    \"\"\"\n",
    "    Returns the album page links for each album in sputnik all time list.\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = \"https://www.sputnikmusic.com\"\n",
    "    table = soup.find(\"tr\", class_=\"alt1\").parent.parent\n",
    "    \n",
    "    links = [urljoin(base_url, a.get('href')) for a in table.find_all(\"a\")]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_data(links, start, num = 20):\n",
    "    \"\"\"\n",
    "    Collect data for release year and genres for Sputnik albums.\n",
    "    \n",
    "    Params:\n",
    "    - links: Full list of album page links\n",
    "    - start: index of first element in list to iterate over. First index is 0\n",
    "    - num: Number of links to iterate over (default is 20)\n",
    "    \"\"\"\n",
    "\n",
    "    base_url = \"https://www.sputnikmusic.com\"\n",
    "\n",
    "    years = []\n",
    "    genres = []\n",
    "\n",
    "    for i in range(start, start + num):\n",
    "        print(f\"Iteration {i}:\")\n",
    "\n",
    "        r = requests.get(links[i])\n",
    "        if r.status_code == 200:\n",
    "            # Find the correct div\n",
    "            soup = BeautifulSoup(r.content, \"lxml\")\n",
    "            div = soup.find(\"div\", {\"style\": re.compile(\"silverbar\")})\n",
    "\n",
    "            # Need to check case if we are on a review page or on a soundoff page\n",
    "            if div is not None:\n",
    "                # We are on a review page (usual case)\n",
    "                a = div.find(\"a\", {\"href\": re.compile(\"bands\")})\n",
    "                \n",
    "                pattern = re.compile(r\"\\d+\")\n",
    "                m = pattern.search(div.find(\"p\").text)\n",
    "                year = m.group()\n",
    "            \n",
    "            else:\n",
    "                # We are on a soundoff page\n",
    "                tab = soup.find(\"table\", class_=\"tableborder\")\n",
    "                a = tab.find(\"a\", {\"href\": re.compile(\"bands\")})\n",
    "                \n",
    "                b = tab.find(\"b\", text=re.compile(r\"\\d+\"))\n",
    "                year = b.text\n",
    "                    \n",
    "            artist_link = urljoin(base_url, a.get('href'))\n",
    "            years.append(year)\n",
    "\n",
    "            print(f\"Found album release year: {year}\")\n",
    "\n",
    "            # Wait 3 seconds before visiting artist page\n",
    "            time.sleep(3)\n",
    "            r2 = requests.get(artist_link)\n",
    "\n",
    "            if r2.status_code == 200:\n",
    "                print(f\"Visiting artist page: {artist_link}\")\n",
    "                soup = BeautifulSoup(r2.content, \"lxml\")\n",
    "\n",
    "                genre_div = soup.find(\"div\", class_=\"tagwrap\")\n",
    "                anchors = genre_div.find_all(\"a\")\n",
    "                gen = [a.string.strip() for a in anchors]\n",
    "                genres.append(gen)\n",
    "\n",
    "                print(f\"Found genres: {gen}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Get request to {artist_link} failed.\")\n",
    "                print(f\"Status code: {r2.status_code}\")\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            print(f\"Get request to {links[i]} failed.\")\n",
    "            print(f\"Status code: {r.status_code}\")\n",
    "            break\n",
    "\n",
    "        # Wait 3 seconds before next iteration\n",
    "        time.sleep(3)\n",
    "        \n",
    "    return years, genres\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates new empty list for years and genres\n",
    "# Do not run if you only wish to extend already existent list\n",
    "years, genres = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10:\n",
      "Found album release year: 1969\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/King-Crimson/82/\n",
      "Found genres: ['Progressive Rock', 'Jazz Fusion', 'Experimental']\n",
      "Iteration 11:\n",
      "Found album release year: 1969\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/The-Beatles/73/\n",
      "Found genres: ['Rock', 'Pop', 'Psychedelic']\n",
      "Iteration 12:\n",
      "Found album release year: 1997\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/Radiohead/86/\n",
      "Found genres: ['Alternative Rock', 'Electronic', 'Experimental']\n",
      "Iteration 13:\n",
      "Found album release year: 1973\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/Pink-Floyd/110/\n",
      "Found genres: ['Progressive Rock', 'Psychedelic']\n",
      "Iteration 14:\n",
      "Found album release year: 1995\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/GZA/3419/\n",
      "Found genres: ['Hip-Hop']\n",
      "Iteration 15:\n",
      "Found album release year: 1972\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/David-Bowie/493/\n",
      "Found genres: ['Rock', 'Experimental', 'Post Punk']\n",
      "Iteration 16:\n",
      "Found album release year: 1972\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/Yes/65/\n",
      "Found genres: ['Progressive Rock', 'Psychedelic', 'Pop Rock']\n",
      "Iteration 17:\n",
      "Found album release year: 1995\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/Death/657/\n",
      "Found genres: ['Death Metal', 'Progressive Metal', 'Thrash Metal']\n",
      "Iteration 18:\n",
      "Found album release year: 1801\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/Ludwig-van-Beethoven/6689/\n",
      "Found genres: ['Classical', 'Bluegrass']\n",
      "Iteration 19:\n",
      "Found album release year: 1808\n",
      "Visiting artist page: https://www.sputnikmusic.com/bands/Ludwig-van-Beethoven/6689/\n",
      "Found genres: ['Classical', 'Bluegrass']\n",
      "['1975', '1824', '1963', '1994', '1959', '1993', '1901', '1965', '1791', '1990', '1969', '1969', '1997', '1973', '1995', '1972', '1972', '1995', '1801', '1808']\n",
      "[['Progressive Rock', 'Psychedelic'], ['Classical', 'Bluegrass'], ['Jazz', 'Experimental'], ['Hip-Hop'], ['Jazz', 'Jazz Fusion', 'Experimental'], ['Hip-Hop'], ['Classical'], ['Jazz', 'Experimental'], ['Classical', 'Bluegrass'], ['Thrash Metal', 'Heavy Metal', 'Metal'], ['Progressive Rock', 'Jazz Fusion', 'Experimental'], ['Rock', 'Pop', 'Psychedelic'], ['Alternative Rock', 'Electronic', 'Experimental'], ['Progressive Rock', 'Psychedelic'], ['Hip-Hop'], ['Rock', 'Experimental', 'Post Punk'], ['Progressive Rock', 'Psychedelic', 'Pop Rock'], ['Death Metal', 'Progressive Metal', 'Thrash Metal'], ['Classical', 'Bluegrass'], ['Classical', 'Bluegrass']]\n"
     ]
    }
   ],
   "source": [
    "links = get_album_links(soup_all_time)\n",
    "\n",
    "# Choose starting position, get_other_data() gets only 20 data points to avoid making too many requests at a time \n",
    "new_years, new_genres = get_other_data(links, 20)\n",
    "years.extend(new_years)\n",
    "genres.extend(new_genres)\n",
    "\n",
    "print(years)\n",
    "print(genres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
